import requests
from bs4 import BeautifulSoup
import re


# URL'yi alalım ve sayfanın HTML içeriğini çekelim
def GetAndResultsURL(url)
    headers = {
        User-Agent Mozilla5.0 (Windows NT 10.0; Win64; x64) AppleWebKit537.36 (KHTML, like Gecko) Chrome58.0.3029.110 Safari537.3
    }
    response = requests.get(url, headers=headers)

    if response.status_code == 200
        return BeautifulSoup(response.content, 'html.parser')
    else
        print(Sayfa alınamadı, url)
        return None


# Hedef URL
base_url = 'httpswww.thieme-connect.comproductsejournalsissue10.1055s-007-34039'

# Ana sayfayı alalım
html = GetAndResultsURL(base_url)

if html
    # Yılları bul
    years = html.find_all('a', href=True)
    for year_link in years
        if 'issues' in year_link['href']
            year_url = 'httpswww.thieme-connect.com' + year_link['href']
            year = year_link.text.strip()

            # Yıl sayfasına istek yap
            year_html = GetAndResultsURL(year_url)

            if year_html
                # Sayılara ait linkleri bul
                issue_links = year_html.find_all('a', href=True)

                # Her sayı için döngü
                for link in issue_links
                    if 'issue' in link['href']  # Yalnızca issue linklerini çek
                        issue_url = 'httpswww.thieme-connect.com' + link['href']

                        # Sayı sayfasını çekelim
                        issue_html = GetAndResultsURL(issue_url)

                        if issue_html
                            # Her sayfanın articleListing div'ini bul
                            article_listing = issue_html.find('div', class_='articleListing')

                            if article_listing
                                # listItem scientific div'lerinden bağlantıları bul ve href'i güncelle
                                for links in article_listing.findAll(div, {class listItem scientific})
                                    if links.a and links.a[href].startswith(products)
                                        # href değerini doğrudan güncelle
                                        links.a[href] = httpswww.thieme-connect.com + links.a[href]

                                # li etiketleri içindeki bağlantıları da bul ve href'i güncelle
                                for li in article_listing.findAll(li, {class option})
                                    if li.a and li.a[href].startswith(products)
                                        li.a[href] = httpswww.thieme-connect.com + li.a[href]


                                # Geçersiz karakterleri temizlemek için regex kullanıyoruz
                                def sanitize_filename(filename)
                                    # Dosya isimlerinde geçerli olmayan karakterleri boşluk ile değiştir
                                    return re.sub(r'[]', '_', filename)


                                # Dosya ismi için başlık belirle
                                issue_title = sanitize_filename(link.text.strip().replace(, -).replace( , _))

                                # HTML dosyasına yaz
                                with open(f'{year}_{issue_title}.html', 'w', encoding='utf-8') as file
                                    file.write(article_listing.prettify())

                                print(f{year}_{issue_title}.html dosyası oluşturuldu.)
                            else
                                print(f'articleListing' div'i bulunamadı {issue_url})
                        else
                            print(fSayı sayfası alınamadı {issue_url})
            else
                print(fYıl sayfası alınamadı {year_url})
else
    print(fAna sayfa alınamadı {base_url})
